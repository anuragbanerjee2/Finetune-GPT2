{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training data from PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_qa_data import papers_to_data\n",
    "import os\n",
    "if not os.path.exists('./data'):\n",
    "    os.makedirs('./data')\n",
    "pdf_folder = './pdfs'\n",
    "papers_to_data(folder_path='./pdfs',output_file='./data/train.txt',page_pairs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anurag/projects/gpt2-rag/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/anurag/projects/gpt2-rag/.venv/lib/python3.12/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:06<00:00,  3.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 6.6707, 'train_samples_per_second': 2.399, 'train_steps_per_second': 0.3, 'train_loss': 7.174695014953613, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from finetune_gpt2 import finetune\n",
    "finetune(model_name='gpt2',text_file='./data/train.txt',model_dir='./model/gpt2-124m-ft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import Inference\n",
    "\n",
    "inst = Inference('./model/gpt2-124m-ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Q]what is the paper about? [A]by the way, I think it\\'s a paper that is published in the journal PLoS One, which is about two pages long. I don\\'t know a lot about the paper and what it\\'s about or what it\\'s about, as far as I know.\" (He declined to discuss any of this in advance.)\\n\\nAdvertisement\\n\\n\\nThe paper in question uses a small dataset of nearly 100 documents from the American Psychiatric Association, including at'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst.get_answer('[Q]what is the paper about? [A]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
